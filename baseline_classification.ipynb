{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train = preprocess(df_train, df_test, use_ohe=True, filter_features=True, use_scaling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_pipe = Pipeline([\n",
    "    ('bnb', BernoulliNB())\n",
    "])\n",
    "\n",
    "dt_pipe = Pipeline([\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "etc_pipe = Pipeline([\n",
    "    ('etc', ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "gnb_pipe = Pipeline([\n",
    "    ('gnb', GaussianNB())\n",
    "])\n",
    "\n",
    "kn_pipe = Pipeline([\n",
    "    ('kn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "svc_pipe = Pipeline([\n",
    "    ('svc', LinearSVC())\n",
    "])\n",
    "\n",
    "lr_pipe = Pipeline([\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [bnb_pipe, dt_pipe, etc_pipe, gnb_pipe, kn_pipe, lr_pipe, rf_pipe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline(X, y, pipeline):\n",
    "    rskf = StratifiedKFold(n_splits=5, random_state=1)\n",
    "    rmse_scores = []\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_test, pipeline.predict(X_test))))\n",
    "\n",
    "    print(\"kfolds rmse: {0}, mean rmse: {1}\".format(\n",
    "        str([str(round(x, 3)) for x in sorted(rmse_scores)]),\n",
    "        round(np.mean(rmse_scores), 3)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BernoulliNB\n",
      "kfolds rmse: ['1.572', '1.579', '1.581', '1.586', '1.589'], mean rmse: 1.581\n",
      "-----------------------------------------------------------------------\n",
      "Model: DecisionTreeClassifier\n",
      "kfolds rmse: ['1.275', '1.293', '1.295', '1.303', '1.321'], mean rmse: 1.297\n",
      "-----------------------------------------------------------------------\n",
      "Model: ExtraTreesClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfolds rmse: ['1.266', '1.268', '1.27', '1.271', '1.275'], mean rmse: 1.27\n",
      "-----------------------------------------------------------------------\n",
      "Model: GaussianNB\n",
      "kfolds rmse: ['1.33', '1.36', '1.47', '1.627', '1.646'], mean rmse: 1.487\n",
      "-----------------------------------------------------------------------\n",
      "Model: KNeighborsClassifier\n",
      "kfolds rmse: ['1.347', '1.352', '1.355', '1.362', '1.373'], mean rmse: 1.358\n",
      "-----------------------------------------------------------------------\n",
      "Model: LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfolds rmse: ['1.573', '1.592', '1.597', '1.6', '1.603'], mean rmse: 1.593\n",
      "-----------------------------------------------------------------------\n",
      "Model: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whiteRa2bit/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfolds rmse: ['1.222', '1.228', '1.228', '1.238', '1.241'], mean rmse: 1.231\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "objects_to_calculate = 50000\n",
    "for pipeline in pipelines:\n",
    "    print(\"Model:\", type(pipeline[0]).__name__)\n",
    "    test_pipeline(X_train[:objects_to_calculate], y_train[:objects_to_calculate], pipeline)\n",
    "    print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    (\"bnb\", bnb_pipe),\n",
    "    (\"dt\", dt_pipe),\n",
    "    (\"etc\", etc_pipe),\n",
    "    #(\"gnb\", gnb_pipe),\n",
    "    (\"kn\", kn_pipe),\n",
    "    #(\"svc\", svc_pipe),\n",
    "    #(\"lr\", lr_pipe),\n",
    "    (\"rf\", rf_pipe),\n",
    "]\n",
    "\n",
    "mixed_pipe = Pipeline([\n",
    "    (\"voting\", VotingClassifier(classifiers, voting=\"soft\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfolds rmse: ['1.208', '1.214', '1.215', '1.227', '1.228'], mean rmse: 1.218\n"
     ]
    }
   ],
   "source": [
    "test_pipeline(X_train_transformed.values[:objects_to_calculate], y_train[:objects_to_calculate], mixed_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class ShuffleVoter(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"\n",
    "       scikit-learn based voting aggregation ensembling.\n",
    "       Using bootstrapping creates a set of models, differing only by which data sample they are fed\n",
    "       \"\"\"\n",
    "\n",
    "    def __init__(self, models):\n",
    "        \"\"\"\n",
    "        model - base model ( or a pipeline ) ( unfitted )\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        \n",
    "    def ensemble_predictions(self, predictions, weights, type_=\"harmonic\"):\n",
    "        \"\"\"\n",
    "        Combines probabilistic class estimates using a variety of strategies.\n",
    "        Linear, harmonic, geometric and rank averaging are supported at this moment. \n",
    "        Insipred by well known Abhishek's kernel on Kaggle \n",
    "        model - base model ( or a pipeline ) ( unfitted )\n",
    "        \"\"\"\n",
    "        assert np.isclose(np.sum(weights), 1.0)\n",
    "        if type_ == \"linear\":\n",
    "            res = np.average(predictions, weights=weights, axis=0)\n",
    "        elif type_ == \"harmonic\":\n",
    "            res = np.average([1 / p for p in predictions], weights=weights, axis=0)\n",
    "            return 1 / res\n",
    "        elif type_ == \"geometric\":\n",
    "            numerator = np.average(\n",
    "                [np.log(p) for p in predictions], weights=weights, axis=0\n",
    "            )\n",
    "            res = np.exp(numerator / sum(weights))\n",
    "            return res\n",
    "        elif type_ == \"rank\":\n",
    "            res = np.average([rankdata(p) for p in predictions], weights=weights, axis=0)\n",
    "            return res / (len(res) + 1)\n",
    "        return res\n",
    "\n",
    "\n",
    "    def fit( self, X, y, n_boots = 14, test_size = 100 ):\n",
    "        \"\"\"\n",
    "        n_boots - number of bootstrapping iterations ( and respective models built)\n",
    "        \"\"\"\n",
    "        self.clfs  = []\n",
    "        for i, model in zip(range(n_boots), cycle(self.models)):\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split( X, y, test_size=test_size, random_state=3521 + i*10)\n",
    "\n",
    "            pa_clf = model\n",
    "            pa_clf.fit(X_tr, y_tr)\n",
    "\n",
    "            self.clfs.append(pa_clf)\n",
    "\n",
    "    def predict( self, X, ensemble_type = 'rank'):\n",
    "        # TODO: nonuniform weights\n",
    "        \n",
    "        n_boots = len( self.clfs)\n",
    "        preds = [ clf.predict(X) for clf in self.clfs ]\n",
    "        return self.ensemble_predictions( preds, np.ones(n_boots)*(1/float(n_boots)), ensemble_type)\n",
    "    \n",
    "    def predict_proba( self, X, ensemble_type = 'rank' ):\n",
    "        n_boots = len( self.clfs)\n",
    "        preds = [ clf.predict_proba(X) for clf in self.clfs ]\n",
    "        return self.ensemble_predictions( preds, np.ones(n_boots)*(1/float(n_boots)), ensemble_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
